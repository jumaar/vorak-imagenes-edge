## Guia completa MODULO-NEVERA
- MODULO-SENSORES : este modulo es una configuracion hecha en esp32 (leer documentacion.md MODULO-SENSORES ), este nos envia un reporte cada 30 segundos con el estado de la nevera, y 2 tipos de eventos a.cuando abre  cierra la puerta b. cuando hay un cambio de peso.

- HARDWARE : se acondiciona un pc portatil de buena pantalla 15.5 " para el sistema de kiosco , minimo core i3 con 4gb de ram , se instala SO linux Debian 13, se procesa toda la informacion recibida de los sensores y de las camaras web con opturador global shutter monocromaticas de alta captura, pueden ser 2  mas camaras es solo modificar en app.py el CAMERA_INDICES = [0,1,2,3]

- ADMINISTRACION : Se utiliza un tunnel ssh desde un pc cliente. por medio de cloudflared se realiza la configuracion del sudominio de cada nueva nevera que se a√±ada a red , clouflared se encarga de hacernos la conexion segura a cada dispositivo para la administracion, el archivo ``config-tunnel-client-ser.md`` es la guia completa para dejar la conexion lista con el servidor. siempre que recibamos una calificacion baja de captura de producto se debe ingresar a la nevera para a revision manual de las capturas tomadas de a secion fallida , cada  secion se guarda con un id unico. la nevera tiene un boton de tara , el cual lleva a cero la bascula (esta se debe tener vacia a momneto de la tara) 

- LOGICA : app.py es el cerebro que se encarga de procesar todos los eventos y enviar al backend las respuestas de cada evento , tenemos implementado un sistema de falla de comunicacion persistente, tenemos sistema de logs, tenemos sistema de captura de secion de identificacion de productos con dudosa evaluacion el cual guarda en el servidor las imagenes para una revision posterior por un humano o una ia para verificar cual fue el fallo en la captura y la decision de que producto fue el que salio o entro de la nevera,

- KIOSK: ``modulo-kiosk-edge`` tenemos un pantalla adactada que muestra en modo kiosko informacion de la nevera y publicidad este modulo se conecta con ``modulo-kiosk-admin``que es el encargado de poner de manera inteligente la publicidad ( si en una nevera hay mucho chorizo esta por vencer --> el sistema coloca en descuento el producto y pone la imagen de promocion de chorizo en la nevera )
documentacion ``documentacion-kiosk-admin.md``

- .env:  ``FRIDGE_ID="NEVERA-001-SANTAROSA"`` simpre modificar este id para cada nevera
``BASE_BACKEND_URL="https://9dfd069ea59e.ngrok-free.app"`` se coloca solo la url de la api , el resto ya lo manejca cada script.
``FRIDGE_SECRET="una-clave-secreta-muy-larga-y-unica"`` Clave secreta para la autenticaci√≥n JWT.

-JWT: Integrado. El sistema ahora usa autenticaci√≥n JWT para todas las peticiones al backend.
 
   




## TAREAS  --> V 0.3 

nota: en este apartado se colocan ideas y posibles mejoras a futuro , cuando se coloca una queda pendiente, si la tarea se realiza esta se elinina de aca y se implementa inmediatamente en la docuentacion si la mejora fuera positiva.( si esta vacio no hay nada pendiente)

- En que version de este modulo estamos para git?  -> 0.3

- crear un servidor para el manejo .env y que cada nevera se conecte a el para cargar las claves  y las variables de entorno y asi Eliminar la librer√≠a python-dotenv usamos swarm





## USO DIARIO. 

# Con√©ctate usando el subdominio √∫nico de la nevera.
``ssh nevera1@ssh-nevera1.lenstextil.com``

# Verificar el estado de tu aplicaci√≥n. 
``sudo systemctl status nevera.service``

# parar el servicio de la app.py
``sudo systemctl stop nevera.service``

# VERFICAR los LOGS de tu aplicaci√≥n. 
``El '-n 100' muestra las √∫ltimas 100 l√≠neas, y '--no-pager' lo imprime directo.
``journalctl -u nevera.service -n 100 --no-pager``

este comando muestra los logs desde el ultimo reinicio
`journalctl -b -u nevera.service`

ver losg en tiempo real 
``journalctl -f -u nevera.service``

``# El '-n 20' muestra las √∫ltimas 20 l√≠neas.
``tail -n 20 ~/MODULO-NEVERA/fridge_service.log``

# gestion de archivos en el servidor app
``cd ~/MODULO-NEVERA/``  modificar archivo de configuracion  ``nano app.py`` 
reiniciar despues ``sudo systemctl restart nevera.service``

# Entorno virtual para actualizar librerias

1. `` cd ~/MODULO-NEVERA/``  
2. Activa el entorno para "abrir la caja de herramientas".``source venv/bin/activate``

3. Instala la nueva herramienta. Notar√°s el prefijo (venv). 
(venv) nevera1@...:~$ pip install opencv-python requests pyserial python-dotenv Flask PyJWT

4. desactivar el entorno.
(venv) nevera1@...:~$ deactivate

5. reiniciar de nuevo 
 ``sudo systemctl restart nevera.service``

# copiar carpetas o archivos desde el servidor cambiar el --> nevera1@ssh-nevera1.lenstextil.com

Con este comando se pueden copiar carpetas o archivos desde el servidor desde linux a wimdows o al pc de administracion. 
`` scp -r nevera1@ssh-nevera1.lenstextil.com:/home/nevera1/MODULO-NEVERA/review_queue/ .``
nota : estar ubicados en en la terminal donde se quiere guardar la carpeta

 Pasar el app.py al servidor
``scp "D:\Desktop\GITHUB jumaar\vorak\MODULO-NEVERA\app.py" nevera1@ssh-nevera1.lenstextil.com:/home/nevera1/MODULO-NEVERA/``

Pasar  la carpeta completa del kisko al servidor
``scp -r "D:\Desktop\GITHUB jumaar\vorak\MODULO-NEVERA\modulo-kiosk-edge" nevera1@ssh-nevera1.lenstextil.com:~/MODULO-NEVERA`` 











## M√≥dulo de Procesamiento para Nevera Inteligente app.py

### 1. Descripci√≥n General / modulos importantes 3. y 8.

Este programa en Python act√∫a como el "cerebro" del sistema de la nevera inteligente. Se ejecuta en un PC (o similar) conectado a la nevera y es responsable de:  

-   **Comunicarse** con el microcontrolador ESP32 para recibir eventos de sensores (puerta, peso, temperatuta). COM1 COM2 COM3 para windows y SERIAL_PORT = '/dev/ttyUSB0' para linux.
-   **Controlar** las c√°maras USB global shutter monocromaticas para capturar im√°genes durante una interacci√≥n.
-   **Procesar** los datos de la sesi√≥n de apertura de puerta para correlacionar cambios de peso con productos (identificados por marcadores ArUco).
-   **Enviar de forma robusta** las transacciones y reportes de estado a un servidor backend, con un sistema de reintentos y persistencia offline para no perder ninguna transacci√≥n.
-   **Registrar** toda la actividad y los errores en archivos de log para facilitar la monitorizaci√≥n y el diagn√≥stico se puede usar un servicio de monitoreo como dataDog o New Relic.
-   **Auditar** sesiones de baja confianza guardando las im√°genes capturadas para una revisi√≥n posterior (carpeta review_queue) , ya sea manual o por otra IA.

El sistema est√° dise√±ado para ser robusto y manejar m√∫ltiples interacciones r√°pidas sin perder datos.

### 2. Arquitectura: El Mesero, los Cocineros y el Equipo de Log√≠stica

Para garantizar que el sistema siempre est√© listo para una nueva apertura de puerta, incluso si el procesamiento anterior no ha terminado, se utiliza un modelo de dos tipos de hilos (threads):

a.  **El Mesero (Hilo Principal)**: Es el hilo principal de la aplicaci√≥n. Su √∫nica tarea es esperar eventos. Cuando la puerta se abre, inicia una sesi√≥n de captura. Cuando la sesi√≥n termina, empaqueta todos los datos y se los entrega a un "Cocinero". Vuelve inmediatamente a esperar la siguiente apertura de puerta.

b.  **Los Cocineros (Hilos de Procesamiento)**: Por cada sesi√≥n terminada, el "Mesero" crea un nuevo hilo "Cocinero" (`session_processing_thread`). Este hilo realiza el trabajo pesado: analiza las im√°genes, correlaciona los datos y, si deduce una transacci√≥n, la entrega al "Cartero".

c.  **El Cartero (Hilo de Carga a la API)**: El `api_uploader_thread` es responsable de enviar los datos al backend.
    -   Toma los "trabajos" de una cola.
    -   Para transacciones cr√≠ticas, si el env√≠o falla, lo reintenta varias veces.
    -   Si los reintentos fallan, guarda el paquete en un archivo local y se lo pasa al "Almacenista".

d.  **El Almacenista Offline (Hilo de Env√≠o Offline)**: El `offline_sender_thread` es un trabajador paciente. Peri√≥dicamente revisa la carpeta `offline_queue`. Si encuentra paquetes pendientes y hay conexi√≥n a internet, los env√≠a al backend, asegurando que ninguna transacci√≥n se pierda, incluso si la aplicaci√≥n se reinicia.

Esta arquitectura asegura que **abrir la puerta r√°pidamente varias veces no causar√° errores** y que **ninguna transacci√≥n de inventario se perder√°** por fallos de red.

### 3. M√≥dulos de C√≥digo

El c√≥digo se organiza en las siguientes funciones y hilos principales dentro de `app.py`:

-  **Hilos de Infraestructura (Trabajadores de Fondo)**

-   `serial_reader_thread()`: El "Recepcionista del ESP32". Lee continuamente los datos de los sensores desde el puerto serie y los pone en una cola.
-   `camera_worker_thread()`: El "Vigilante". Gestiona una c√°mara, manteni√©ndola lista y guardando fotogramas cuando se le ordena.
-   `api_uploader_thread()`: El "Cartero". Env√≠a los datos al backend, gestionando reintentos para transacciones cr√≠ticas.
-   `offline_sender_thread()`: El "Almacenista". Procesa la cola de env√≠os guardados en disco cuando la conexi√≥n se restablece.
-   `product_database_updater_thread()`: El "Gerente de Inventario". Actualiza peri√≥dicamente la base de datos de productos desde el backend.

-  **Hilos de Procesamiento de Sesi√≥n (Los "Cocineros")** 

-   `session_processing_thread()`: El "Cocinero Jefe". Orquesta el an√°lisis completo de una sesi√≥n en un hilo dedicado para no bloquear el sistema.
-   `process_images_for_arucos()`: El "Cocinero Especialista en Visi√≥n". Procesa todas las im√°genes de una sesi√≥n para detectar los marcadores ArUco.

-  **Hilos de Funciones Principales de L√≥gica y Orquestaci√≥n**

-   `correlate_and_prepare_upload()`: **LA FUNCI√ìN M√ÅS IMPORTANTE**. Act√∫a como el "Cocinero de L√≥gica de Negocio" que orquesta la secuencia de an√°lisis para deducir las transacciones. Llama a las siguientes sub-funciones:
    -   `_synchronize_timestamps()`: Alinea los timestamps de los sensores con el reloj del PC.
    -   `_analyze_aruco_frequency()`: Asigna un rating de confianza global a cada ArUco visto en la sesi√≥n.
    -   `_build_state_intervals()`: Divide la sesi√≥n en intervalos de tiempo basados en los cambios de peso y crea un inventario de ArUcos para cada uno.
    -   `find_best_candidates()`: Selecciona los candidatos visuales m√°s probables para un cambio de peso.
    -   `_deduce_initial_transactions()`: Genera la primera lista de transacciones candidatas comparando los inventarios entre intervalos.
    -   `_validate_and_resolve_transactions()`: Valida las transacciones por peso y resuelve ambig√ºedades, incluyendo la l√≥gica de "swap temporal".
    -   `_consolidate_transactions()`: Limpia el resultado final eliminando transacciones de "ruido" (movimientos netos de cero).
    -   `_finalize_session()`: Prepara el lote final para su env√≠o a la cola del "Cartero".

-  **Hilos de Funciones de Soporte y Utilidades**

-   `setup_logging()`: Configura un sistema de registro profesional que escribe en consola y en archivos rotativos.
-   `load_initial_product_database()`: Carga la lista de productos al iniciar el sistema, ya sea desde el backend o desde una cach√© local.
-   `_save_images_for_review()`: Guarda las im√°genes de una sesi√≥n cuando se detectan transacciones de baja confianza para auditor√≠a `low_weight_mismatch` o `low_no_match`.
-   `_send_payload()` y `_save_payload_for_offline_sending()`: Funciones auxiliares para el "Cartero" que realizan el env√≠o HTTP y el guardado en disco.
-   **Bucle Principal (`if __name__ == "__main__"`)**: Act√∫a como el "Mesero". Gestiona la m√°quina de estados principal (`IDLE`/`CAPTURING`) y delega el trabajo pesado a los hilos "Cocinero".

### 4. Configuraci√≥n

Todas las configuraciones principales se encuentran al inicio del archivo `app.py`:

-   `SERIAL_PORT`: Puerto COM o tty donde est√° conectado el ESP32.
-   `CAMERA_INDICES`: Lista de los √≠ndices de las c√°maras a utilizar (ej. `[0, 1]` para dos c√°maras).
-   `CAPTURE_TIMEOUT_SECONDS`: Segundos de inactividad de peso para terminar una sesi√≥n de captura.
-   `BACKEND_URL`: La URL del servidor donde se enviar√°n los resultados.
-   `MAX_UPLOAD_RETRIES`: N√∫mero de reintentos inmediatos antes de guardar un env√≠o para m√°s tarde.
-   `OFFLINE_CHECK_INTERVAL_SECONDS`: Cada cu√°ntos segundos el "Almacenista" revisa si hay env√≠os pendientes.
-   `REVIEW_QUEUE_PATH`: Carpeta donde se guardan las im√°genes de las sesiones que requieren revisi√≥n.

### 5. Flujo de Operaci√≥n

1.  **IDLE**: El sistema espera eventos del ESP32.
    -   Si recibe un `door_change` con estado `open`, pasa al estado **CAPTURING**.
    -   Si recibe un `status_report` o `tare_button`, lo pone en la cola de subida para un env√≠o no cr√≠tico.
2.  **CAPTURING**: Al abrirse la puerta:
    -   Se activan las c√°maras para que empiecen a guardar fotogramas.
    -   Se registran todos los eventos de `weight_change`.
    -   La captura termina si llega un evento `door_change` con estado `closed` o si transcurre el `CAPTURE_TIMEOUT_SECONDS` sin cambios de peso.
3.  **PROCESSING**:
    -   El "Mesero" (bucle principal) empaqueta los datos de la sesi√≥n e inicia un nuevo hilo "Cocinero" (`session_processing_thread`).
    -   El "Mesero" vuelve inmediatamente al estado **IDLE**.
    -   El "Cocinero" (`session_processing_thread`) realiza el an√°lisis de correlaci√≥n (llamando a `correlate_and_prepare_upload`) y pone las transacciones resultantes en la cola de subida.
4.  **UPLOADING (Gesti√≥n de Env√≠o)**:
    -   El hilo "Cartero" (`api_uploader_thread`) toma los trabajos de la cola.
    -   Si un trabajo es cr√≠tico (`type: "transaction"`), intenta enviarlo. Si falla, reintenta `MAX_UPLOAD_RETRIES` veces.
    -   Si los reintentos fallan, guarda el trabajo en la carpeta `offline_queue`.
    -   El hilo "Almacenista" (`offline_sender_thread`) revisa esa carpeta cada `OFFLINE_CHECK_INTERVAL_SECONDS`. Cuando hay conexi√≥n, env√≠a los trabajos pendientes y los elimina.

### 6. L√≥gica de Correlaci√≥n (`correlate_and_prepare_upload`)

Esta funci√≥n orquesta el flujo de an√°lisis para tomar los datos brutos de una sesi√≥n y deducir qu√© productos entraron o salieron. El proceso se divide en pasos claros, cada uno manejado por una sub-funci√≥n:

1.  **Sincronizaci√≥n y An√°lisis Previo**: Se sincronizan los timestamps y se analiza la frecuencia global de los ArUcos para obtener un rating de confianza.
1.  **Sincronizaci√≥n y An√°lisis Previo**: Se sincronizan los timestamps (`_synchronize_timestamps`) y se analiza la frecuencia global de los ArUcos para obtener un rating de confianza (`_analyze_aruco_frequency`).
2.  **Construcci√≥n de Intervalos de Estado (`_build_state_intervals`)**: La sesi√≥n se divide en segmentos de tiempo, usando cada cambio de peso como un punto de corte. Para cada segmento, se crea un "inventario" de los ArUcos vistos.
3.  **Deducci√≥n de Transacciones Iniciales (`_deduce_initial_transactions`)**: Por cada cambio de peso, se comparan los inventarios de ArUcos del intervalo ANTERIOR con el POSTERIOR para generar una lista de transacciones candidatas.
    -   **Si el peso AUMENTA (Producto A√±adido)**: Los candidatos son los ArUcos vistos **ANTES** del cambio de peso. (Raz√≥n: El usuario muestra el producto a la c√°mara y *luego* lo pone en la b√°scula).
    -   **Si el peso DISMINUYE (Producto Retirado)**: Los candidatos son los ArUcos vistos **DESPU√âS** del cambio de peso. (Raz√≥n: El usuario saca el producto de la b√°scula y *luego* lo pasa por la c√°mara al salir).
4.  **Validaci√≥n y Resoluci√≥n de Transacciones (`_validate_and_resolve_transactions`)**: Este es un paso crucial con dos l√≥gicas principales:
    -   **Desambiguaci√≥n Temporal para Intercambios R√°pidos (Nueva L√≥gica Robusta)**:
        -   **Problema**: Se detecta un patr√≥n de `OUT` ambiguo seguido de un `IN` ambiguo con pesos opuestos (ej. -500g y +505g). Esto suele ocurrir cuando un usuario saca un producto y mete otro r√°pidamente.
        -   **Soluci√≥n**: El sistema analiza el intervalo de tiempo entre las dos transacciones. En lugar de confiar en un solo fotograma, toma una muestra de las **primeras detecciones de ArUco** y las **√∫ltimas**.
        -   El ArUco m√°s frecuente en la primera muestra se asigna a la transacci√≥n de **salida (OUT)**.
        -   El ArUco m√°s frecuente en la √∫ltima muestra se asigna a la transacci√≥n de **entrada (IN)**.
        -   Ambas transacciones se marcan con la confianza `high_temporal_swap_confirmed`.
    -   **Validaci√≥n por Peso (Flujo Normal)**: Si el patr√≥n de intercambio no se detecta, se aplica la validaci√≥n est√°ndar. Se compara el `change_g` con el peso nominal de los candidatos de `products.json` para ajustar la confianza (`high_weight_confirmed` o `low_weight_mismatch`).
5.  **Consolidaci√≥n Final (`_consolidate_transactions`)**:
    -   Calcula el movimiento neto de cada producto (ej. +1 si entr√≥, -1 si sali√≥).
    -   Si un producto tiene un movimiento neto de 0 (ej. el cliente lo sac√≥ y lo volvi√≥ a meter), sus transacciones se descartan para no enviar "ruido" al backend.
6.  **Finalizaci√≥n y Env√≠o (`_finalize_session`)**: Se empaquetan las transacciones finales y se determina si la sesi√≥n necesita revisi√≥n.

### 7. Niveles de Confianza
A cada transacci√≥n se le asigna un nivel de confianza para que el backend sepa qu√© tan fiable es la informaci√≥n:

-   `high_temporal_swap_confirmed`: M√°xima confianza. La transacci√≥n fue resuelta usando la l√≥gica de desambiguaci√≥n temporal para un intercambio r√°pido.
-   `high_swap_confirmed`: M√°xima confianza. Se detect√≥ un intercambio de dos productos con peso casi id√©ntico.
-   `high_weight_confirmed`: M√°xima confianza. Evidencia visual y f√≠sica (peso) coinciden.
-   `high`: Alta confianza. Candidato visual claro, pero sin validaci√≥n por peso (ej. el producto no estaba en la DB).
-   `medium_global_tiebreak`: Confianza media. Se asigna cuando hay varios candidatos visuales poco frecuentes y se usa la frecuencia global para desempatar.
-   `low_weight_mismatch`: Baja confianza. La evidencia visual y f√≠sica se contradicen.
-   `low_no_match`: Confianza nula. No se vio ning√∫n ArUco relevante durante el cambio de peso.

### 8. Formato de Datos Enviados al Backend (JSON)

Todos los env√≠os al backend se realizan mediante una petici√≥n `POST` a la `BACKEND_URL`. **Desde la implementaci√≥n de JWT, todas estas peticiones deben incluir una cabecera de autenticaci√≥n `Authorization: Bearer <token>` para ser aceptadas por el backend.** El cuerpo de la petici√≥n, que se muestra en los siguientes ejemplos, es un JSON con la siguiente estructura general:

‚úÖ Caso 1: Transacci√≥n Ideal (Confirmada por Peso)->products.json que se actualiza cada hora desde el backend
Este es el mejor escenario. Se detect√≥ un cambio de peso y solo un producto candidato coincidi√≥ visualmente y por peso.

Escenario: Un cliente saca una libra de un producto (-497g). El sistema la ve claramente y el peso coincide.
```json
{
  "fridge_id": "NEVERA-001-SANTAROSA",
  "batch_id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
  "events": [
    {
      "event": "product_transaction",
      "timestamp": 1757517001234567000,
      "change_g": -497,
      "candidates": [
        {
          "aruco_id": "101",
          "reason": "local_high",
          "nominal_weight_g": 500
        }
      ],
      "confidence": "high_weight_confirmed"
    }
  ]
 }
```


üîÑ Caso 2: Intercambio Resuelto por L√≥gica Temporal
L√≥gica optimizada para flujo OUT -> IN y no al revez (no se necesita)
Este es el caso especial donde un producto es retirado y otro es ingresado con pesos SIMILARES. La l√≥gica de timestamps resuelve la ambig√ºedad.

Escenario: Un cliente saca un producto "A" (-1000g) e inmediatamente despu√©s, coloca un producto "B" (+1000g). El sistema vio primero el ArUco de "A" y al final el de "B". esto se resuelve tomando todos los arucos del intervalo de tiempo posterior al primer evento y asignando los primeros a "A" y los √∫ltimos a "B".   
```json
{
  "fridge_id": "NEVERA-001-SANTAROSA",
  "batch_id": "b2c3d4e5-f6a7-8901-2345-67890abcdef1",
  "events": [
    {
      "event": "product_transaction",
      "timestamp": 1757517105123456000,
      "change_g": -1005,
      "candidates": [
        {
          "aruco_id": "205",
          "reason": "temporal_swap_out_robust",
          "nominal_weight_g": 1000
        }
      ],
      "confidence": "high_temporal_swap_confirmed"
    },
    {
      "event": "product_transaction",
      "timestamp": 1757517109876543000,
      "change_g": 998,
      "candidates": [
        {
          "aruco_id": "310",
          "reason": "temporal_swap_in_robust",
          "nominal_weight_g": 1000
        }
      ],
      "confidence": "high_temporal_swap_confirmed"--> posible mejora en el futuro (esto solo funciona para los valores de peso igual se puede mejorar la logica para que trabaje tambien con valores de peso distintos NOTA: para los pesos distintos lo resuelve products.json, pero A√ëADIR mas robustes a esta logica temporal soluciona el problema de que la tabla de products.json no est√© actualizada)
    }
  ]
}
```
> **Nota**: La l√≥gica de `high_temporal_swap_confirmed` es m√°s robusta cuando los pesos son distintos, ya que la validaci√≥n por peso (`products.json`) ayuda a confirmar. Sin embargo, la l√≥gica temporal por s√≠ sola es una mejora significativa para resolver intercambios de productos de peso id√©ntico que no est√°n actualizados en la base de datos.



‚ùì Caso 3: Ambig√ºedad por Peso
Ocurre cuando un cambio de peso podr√≠a corresponder a varios productos distintos que tienen un peso similar.

Escenario: La b√°scula detecta un cambio de -505g. Tanto el "Jugo de Naranja" (Aruco 45) como el "Yogur de Fresa" (Aruco 48) pesan 500g y ambos fueron vistos.y no esta en el base de datos products.json. El sistema no puede decidir y env√≠a ambos como candidatos.

```json
{
  "fridge_id": "NEVERA-001-SANTAROSA",
  "batch_id": "c3d4e5f6-a7b8-9012-3456-7890abcdef12",
  "events": [
    {
      "event": "product_transaction",
      "timestamp": 1757517220987654000,
      "change_g": -505,
      "candidates": [
        {
          "aruco_id": "45",
          "reason": "local_high",
          "nominal_weight_g": 500
        },
        {
          "aruco_id": "48",
          "reason": "local_medium",
          "nominal_weight_g": 500
        }
      ],
      "confidence": "high"
    }
  ]
}
```


‚ö†Ô∏è Caso 4: Baja Confianza (Discrepancia de Peso)
El sistema ve claramente un producto, pero el cambio de peso medido por la b√°scula no coincide con el peso nominal de ese producto.

Escenario: El sistema ve salir un "Sandwich" (Aruco 77, 200g), pero la b√°scula solo registr√≥ un cambio de -80g.

```json
{
  "fridge_id": "NEVERA-001-SANTAROSA",
  "batch_id": "d4e5f6a7-b8c9-0123-4567-890abcdef123",
  "events": [
    {
      "event": "product_transaction",
      "timestamp": 1757517330123456000,
      "change_g": -80,
      "candidates": [
        {
          "aruco_id": "77",
          "reason": "local_high",
          "nominal_weight_g": 200
        }
      ],
      "confidence": "low_weight_mismatch"  --> **Acci√≥n**: Se ejecuta la funci√≥n `_save_images_for_review` y se guardan las im√°genes en la carpeta `review_queue` para una revisi√≥n manual.

    }
  ]
}
```


üëª Caso 5: Baja Confianza (Sin Evidencia Visual Directa)
La b√°scula detecta un cambio de peso, pero en el intervalo de tiempo relevante no se vio ning√∫n ArUco. El sistema env√≠a una lista de los ArUcos m√°s comunes en la sesi√≥n como posibles "sospechosos".

Escenario: El peso baja -150g, pero el cliente tap√≥ el producto con la mano. El sistema env√≠a los ArUcos m√°s vistos en general durante la sesi√≥n como contexto.

```json
{
  "fridge_id": "NEVERA-001-SANTAROSA",
  "batch_id": "e5f6a7b8-c9d0-1234-5678-90abcdef1234",
  "events": [
    {
      "event": "product_transaction",
      "timestamp": 1757517440987654000,
      "change_g": -150,
      "candidates": [
        {
          "aruco_id": "5",
          "reason": "context_global_high",
          "nominal_weight_g": 330
        },
        {
          "aruco_id": "22",
          "reason": "context_global_medium",
          "nominal_weight_g": 150
        }
      ],
      "confidence": "low_no_match"  --> **Acci√≥n**: Se ejecuta la funci√≥n `_save_images_for_review` y se guardan las im√°genes en la carpeta `review_queue` para una revisi√≥n manual.
    }
  ]
}
```




‚öôÔ∏è Eventos de Estado y Sistema
Estos eventos no est√°n relacionados con una transacci√≥n de productos y se env√≠an de forma individual, fuera de una sesi√≥n de puerta.

‚ÑπÔ∏è Caso 6: Reporte de Estado (type: "status_report")
El ESP32 env√≠a peri√≥dicamente un reporte de su estado actual (peso total, estado de la puerta).

Escenario: Reporte peri√≥dico (30s) mientras la nevera est√° inactiva.

```json
{
  "fridge_id": "NEVERA-001-SANTAROSA",
  "batch_id": "f6a7b8c9-d0e1-2345-6789-0abcdef12345",
  "events": [
    {
      "event": "status_report",
      "timestamp": 1757517550123456000,
      "total_weight_g": 8540,
      "door_status": "closed"
    }
  ]
}
```
‚öñÔ∏è Caso 7: Bot√≥n de Tara Presionado (type: "tare_button")
Un operario presiona el bot√≥n f√≠sico para tarar (poner a cero) la b√°scula.

Escenario: El operario vac√≠a la nevera y presiona el bot√≥n para recalibrar el cero.

```json
{
  "fridge_id": "NEVERA-001-SANTAROSA",
  "batch_id": "a7b8c9d0-e1f2-3456-7890-bcdef1234567",
  "events": [
    {
      "event": "tare_button",
      "timestamp": 1757517660987654000,
      "message": "Tare function executed successfully"
    }
  ]
}
```


###  9. Gesti√≥n de la Base de Datos de Productos

El archivo `products.json` es vital para la validaci√≥n por peso. El sistema lo gestiona de forma autom√°tica y resiliente: NOTA:  BACKEND ES RESPONSABLE DE ACTUALIZARLO.

1.  **Al arrancar**, la aplicaci√≥n siempre intenta descargar la base de datos con ``load_initial_product_database`` desde la `PRODUCT_DATABASE_URL` del backend.
2.  **Si la descarga es exitosa**, crea o sobrescribe el archivo `products.json` local. Este archivo sirve como una cach√© para operaciones futuras.
3.  **Si la descarga falla** (ej. no hay internet), la aplicaci√≥n intenta cargar la √∫ltima versi√≥n guardada en el `products.json` local.
4.  **Si ambos pasos fallan**, la aplicaci√≥n registrar√° un error cr√≠tico pero continuar√° funcionando en un modo degradado, sin la capacidad de validar pesos, asegurando que el resto de las operaciones no se interrumpan.

### 10. Auditor√≠a y Revisi√≥n de Baja Confianza

Para mejorar la fiabilidad del sistema y permitir la correcci√≥n de errores, se ha implementado un mecanismo de auditor√≠a para las transacciones que el sistema no puede resolver con alta certeza.

**¬øCu√°ndo se activa?**

-   Cuando una sesi√≥n de compra resulta en una o m√°s transacciones con confianza `low_weight_mismatch` o `low_no_match`.

**¬øQu√© sucede?**

1.  El sistema marca la sesi√≥n completa para revisi√≥n.
2.  Se crea una carpeta √∫nica dentro de `review_queue`. El nombre de esta carpeta es el mismo `batch_id` que se env√≠a al backend.
3.  **Todas las im√°genes** capturadas durante esa sesi√≥n se guardan en formato `.jpg` dentro de esa carpeta.
4.  El log del sistema registrar√° una advertencia (`‚ùó`) indicando que la sesi√≥n ha sido guardada para revisi√≥n.

Esto permite que un operador humano o un sistema de IA secundario pueda analizar las im√°genes correspondientes a un `batch_id` espec√≠fico para verificar qu√© ocurri√≥ realmente y corregir el inventario si es necesario.




### manjeo de instalacion de camaras

Claro que s√≠! Aqu√≠ tienes un resumen de todo el proceso de depuraci√≥n que hicimos, partiendo del problema que ten√≠as con las rutas de ls -l /dev/v4l/by-path/.

Resumen del Proceso de Depuraci√≥n
El Problema Original:

Identificaste correctamente que para usar dos c√°maras id√©nticas, necesitabas sus rutas por puerto f√≠sico, que obtuviste con ls -l /dev/v4l/by-path/.
El problema fue que estas rutas (ej. pci-0000:00:14.0-usbv2-0:4:1.0-video-index0) contienen dos puntos (:).
Docker Compose usa los dos puntos para separar la ruta del host de la ruta del contenedor (ej. HOST:CONTENEDOR), lo que causaba errores como too many colons o confusing device mapping.
Intentos Fallidos (y por qu√©):

Intentamos usar la "sintaxis larga" en la secci√≥n volumes, pero Docker Compose segu√≠a teniendo problemas para interpretar esas rutas complejas.
Sugerimos usar /dev/v4l/by-id/, pero t√∫ acertadamente nos corregiste, explicando que al ser c√°maras id√©nticas, no ten√≠an IDs √∫nicos, por lo que by-path era la √∫nica opci√≥n.
La Soluci√≥n Definitiva: Reglas udev Como no pod√≠amos cambiar las rutas de las c√°maras ni la sintaxis de Docker, decidimos "enga√±ar" al sistema creando nuestros propios nombres de dispositivo, limpios y predecibles.

¬øQu√© hicimos? Creamos un archivo de reglas en el sistema anfitri√≥n (la nevera) en /etc/udev/rules.d/99-vorak-cameras.rules.
¬øQu√© hace esa regla? Le dice al sistema operativo Linux:
"Cada vez que detectes una c√°mara conectada en el puerto f√≠sico ...usbv2-0:1:1.0..., en lugar de solo llamarla video0, cr√©ale tambi√©n un alias (un acceso directo) llamado /dev/cam_nevera_0".

Hicimos lo mismo para la segunda c√°mara, creando el alias /dev/cam_nevera_1.
El Resultado Final:

Ahora, en tu docker-compose.yml, en lugar de usar las rutas largas y problem√°ticas, usamos nuestros nuevos alias, que son limpios y no tienen dos puntos:
yaml
devices:
  - "/dev/ttyUSB0:/dev/ttyUSB0"
  - "/dev/cam_nevera_0:/dev/video0" # <- Alias limpio y estable
  - "/dev/cam_nevera_1:/dev/video1" # <- Alias limpio y estable
Docker Compose ahora entiende perfectamente estas rutas, y las reglas udev se encargan de que /dev/cam_nevera_0 siempre apunte a la c√°mara correcta, sin importar si reinicias el equipo o desconectas y vuelves a conectar las c√°maras.
En resumen: Creamos alias personalizados y estables en el sistema operativo para evitar los caracteres que confund√≠an a Docker Compose, logrando una configuraci√≥n robusta y funcional. ¬°Fue un gran trabajo en equipo!







-------------------------------------------------------------------------------------------------------


Gu√≠a Definitiva: Configuraci√≥n de M√∫ltiples C√°maras USB Id√©nticas en Linux con Nombres Personalizados
Este documento detalla el proceso validado para instalar dos o m√°s c√°maras USB id√©nticas en un sistema Linux (como Linux Mint), asign√°ndoles nombres de dispositivo permanentes y personalizados para un uso fiable en cualquier aplicaci√≥n, incluyendo Docker.

Paso 1: Verificaci√≥n Inicial del Hardware
El primer paso es confirmar que el sistema operativo reconoce correctamente las c√°maras a nivel de hardware y del subsistema de video.

Instalar Herramientas de Video: Abre una terminal e instala el paquete v4l-utils, que contiene herramientas esenciales para interactuar con dispositivos de video.

Bash

sudo apt update
sudo apt install v4l-utils
Listar Dispositivos de Video: Con ambas c√°maras conectadas, ejecuta el siguiente comando para listar todos los dispositivos de video que el sistema detecta. ¬† 

Bash

v4l2-ctl --list-devices
La salida confirmar√° que ambas c√°maras son reconocidas y mostrar√° los nodos de dispositivo que se les asignan temporalmente (ej. /dev/video0, /dev/video2, etc.). Es normal que cada c√°mara f√≠sica cree dos nodos de video (index0 para captura y index1 para metadatos). ¬† 

Paso 2: Configuraci√≥n de Permisos de Usuario
Para que las aplicaciones puedan acceder a las c√°maras sin privilegios de administrador, el usuario debe pertenecer al grupo video.

A√±adir Usuario al Grupo video: Ejecuta el siguiente comando para a√±adir tu usuario actual al grupo video. La opci√≥n -aG es crucial para a√±adir al grupo sin eliminar al usuario de otros grupos. ¬† 

Bash

sudo usermod -aG video $USER
Aplicar los Cambios: Para que la nueva membres√≠a de grupo tenga efecto, debes cerrar la sesi√≥n por completo y volver a iniciarla. Este paso es obligatorio.

Paso 3: Identificar la Ruta F√≠sica √önica de cada C√°mara
El n√∫cleo del problema con c√°maras id√©nticas es que sus nombres (/dev/videoX) pueden cambiar en cada reinicio. La soluci√≥n es identificarlas por el puerto USB f√≠sico al que est√°n conectadas, que es un identificador estable.

Conecta una c√°mara a la vez: Para evitar confusiones, conecta solo una c√°mara en el puerto deseado.

Obt√©n la informaci√≥n del dispositivo: Usa udevadm para inspeccionar los atributos del dispositivo. Asume que la c√°mara conectada es /dev/video0 (aj√∫stalo si es necesario seg√∫n la salida de v4l2-ctl --list-devices).

Bash

udevadm info -a -n /dev/video0
Encuentra el devpath: En la larga salida del comando, busca en los bloques de "parent device" una l√≠nea que diga ATTRS{devpath}. Este ser√° un n√∫mero corto que identifica la ruta en el bus USB (por ejemplo, 1 o 4). Anota este n√∫mero.

Repite para la otra c√°mara: Desconecta la primera c√°mara, conecta la segunda en su puerto designado y repite los pasos 2 y 3 para encontrar su devpath √∫nico.

Paso 4: Crear una Regla udev para Nombres Personalizados y Permanentes
Con los devpath √∫nicos identificados, creamos una regla udev para que el sistema genere autom√°ticamente enlaces simb√≥licos cortos y significativos cada vez que las c√°maras se conecten.

Crear el Archivo de Reglas: Abre un editor de texto con privilegios de administrador para crear un nuevo archivo de reglas. El n√∫mero 99 asegura que se ejecute despu√©s de las reglas del sistema. ¬† 

Bash

sudo nano /etc/udev/rules.d/99-webcams.rules
Escribir la Regla: Pega el siguiente contenido en el editor, sustituyendo 1 y 4 con los valores de devpath que encontraste en el paso anterior y cam_nevera_0/cam_nevera_1 con los nombres que desees.

Fragmento de c√≥digo

# C√°mara asignada al nombre 'cam_nevera_0' (identificada por el puerto f√≠sico con devpath "4")
SUBSYSTEM=="video4linux", ATTRS{devpath}=="4", KERNEL=="video*", ATTR{index}=="0", SYMLINK+="cam_nevera_0", GROUP="video", MODE="0666"

# C√°mara asignada al nombre 'cam_nevera_1' (identificada por el puerto f√≠sico con devpath "1")
SUBSYSTEM=="video4linux", ATTRS{devpath}=="1", KERNEL=="video*", ATTR{index}=="0", SYMLINK+="cam_nevera_1", GROUP="video", MODE="0666"
ATTRS{devpath}: Identifica el puerto f√≠sico de forma fiable. ¬† 

ATTR{index}=="0": Filtra para aplicar la regla solo al dispositivo de captura de video real, ignorando el de metadatos. ¬† 

SYMLINK+="cam_nevera_0": La acci√≥n principal. Crea el enlace simb√≥lico deseado en el directorio /dev/. ¬† 

Guardar y Cerrar: En nano, presiona Ctrl + X, luego Y para guardar, y finalmente Enter.

Aplicar las Nuevas Reglas: Recarga las reglas de udev y activa los cambios sin necesidad de reiniciar.

Bash

sudo udevadm control --reload-rules
sudo udevadm trigger
Paso 5: Verificaci√≥n Final y Uso
Comprueba que tus nombres personalizados se hayan creado correctamente.

Verificar los Enlaces: Con ambas c√°maras conectadas, lista tus nuevos dispositivos:

Bash

ls -l /dev/cam*
La salida deber√≠a mostrar tus nuevos nombres apuntando a los dispositivos /dev/videoX correspondientes.

Uso en Aplicaciones: ¬°Listo! Ahora puedes usar /dev/cam_nevera_0 y /dev/cam_nevera_1 en todas tus aplicaciones (OBS, scripts, Docker Compose, etc.). Estos nombres son permanentes, predecibles y significativos, resolviendo completamente el problema de la asignaci√≥n aleatoria.


comando
udevadm info -a -n /dev/video0



jumaar@le-id500:~$ v4l2-ctl --list-devices
USB 2.0 Camera: USB Camera (usb-0000:00:14.0-1):
	/dev/video0
	/dev/video1
	/dev/media0

USB 2.0 Camera: USB Camera (usb-0000:00:14.0-4):
	/dev/video2
	/dev/video3
	/dev/media1

jumaar@le-id500:~$ ls -l /dev/cam*
lrwxrwxrwx 1 root root 6 oct  2  2025 /dev/cam_nevera_0 -> video0
lrwxrwxrwx 1 root root 6 oct  2  2025 /dev/cam_nevera_1 -> video2
jumaar@le-id500:~$ ls -l /dev/v4l/by-path/.
total 0
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usb-0:1:1.0-video-index0 -> ../../video0
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usb-0:1:1.0-video-index1 -> ../../video1
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usb-0:4:1.0-video-index0 -> ../../video2
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usb-0:4:1.0-video-index1 -> ../../video3
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usbv2-0:1:1.0-video-index0 -> ../../video0
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usbv2-0:1:1.0-video-index1 -> ../../video1
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usbv2-0:4:1.0-video-index0 -> ../../video2
lrwxrwxrwx 1 root root 12 oct  2  2025 pci-0000:00:14.0-usbv2-0:4:1.0-video-index1 -> ../../video3
jumaar@le-id500:~$ sudo nano /etc/udev/rules.d/99-webcams.rules
[sudo] contrase√±a para jumaar:           
jumaar@le-id500:~$ cat /etc/udev/rules.d/99-webcams.rules
# C√°mara 1 (puerto f√≠sico...-1, que actualmente es video2)
SUBSYSTEM=="video4linux", ATTRS{devpath}=="4", KERNEL=="video*", ATTR{index}=="0", SYMLINK+="cam_nevera_1", GROUP="video", MODE="0666"

# C√°mara 2 (puerto f√≠sico...-4, que actualmente es video0)
SUBSYSTEM=="video4linux", ATTRS{devpath}=="1", KERNEL=="video*", ATTR{index}=="0", SYMLINK+="cam_nevera_0", GROUP="video", MODE="0666"
